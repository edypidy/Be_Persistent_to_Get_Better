{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "하다보면 늘겠지 : 3. Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "7AvrTISzcNYU"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Logistic Binary Classification"
      ],
      "metadata": {
        "id": "H_OK0PZVc14s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "train_x = 5*(2*np.random.random_sample(size=(100,1)) - 1)\n",
        "noise = 2*np.random.random_sample(size=(100,1)) -1\n",
        "\n",
        "train_y = np.where(1/(np.exp(-train_x + noise) + 1) >= 0.5, 1, 0)#.reshape(-1,)"
      ],
      "metadata": {
        "id": "Bk3NZR5rcNWC"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "y8z9nhsrcNTo",
        "outputId": "38b8dd03-95ae-4680-8896-c4c72b0b0fc1"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f5254eabcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "\n",
        "num_epochs = 300\n",
        "learning_rate = 0.05"
      ],
      "metadata": {
        "id": "byWw0nRVcNRX"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model\n",
        "model = nn.Sequential(\n",
        "                      nn.Linear(input_size, output_size),\n",
        "                      nn.Sigmoid()\n",
        "                     )"
      ],
      "metadata": {
        "id": "QfLq_6D0cNOt"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "JImgnlOdcNMC"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    input = torch.Tensor(train_x)\n",
        "    target = torch.Tensor(train_y)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(input)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%20 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss : {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGOxCiyCcNJa",
        "outputId": "bcbdfdcf-208f-46dc-cedf-93593c922077"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/300], Loss : 0.3074\n",
            "Epoch [40/300], Loss : 0.2226\n",
            "Epoch [60/300], Loss : 0.1921\n",
            "Epoch [80/300], Loss : 0.1756\n",
            "Epoch [100/300], Loss : 0.1649\n",
            "Epoch [120/300], Loss : 0.1574\n",
            "Epoch [140/300], Loss : 0.1517\n",
            "Epoch [160/300], Loss : 0.1472\n",
            "Epoch [180/300], Loss : 0.1436\n",
            "Epoch [200/300], Loss : 0.1406\n",
            "Epoch [220/300], Loss : 0.1381\n",
            "Epoch [240/300], Loss : 0.1359\n",
            "Epoch [260/300], Loss : 0.1340\n",
            "Epoch [280/300], Loss : 0.1323\n",
            "Epoch [300/300], Loss : 0.1309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[0].bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVq7xEO-qmEb",
        "outputId": "8fa5772b-7f49-4ac1-c83f-abd3ce918b36"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.0138], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAIPe2Zp_Og",
        "outputId": "ce2f8487-a688-4799-d00e-0f830b7138d2"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1.7577]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = 5*(np.random.random_sample(size=(5,1))*2 - 1)\n",
        "test_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fSBm3aZp2Kw",
        "outputId": "21c57078-6cce-4ce6-ac48-a2f7031be456"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.32750369],\n",
              "       [ 1.79392773],\n",
              "       [-0.46303155],\n",
              "       [ 0.36579211],\n",
              "       [ 3.96671293]])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(torch.Tensor(test_x))\n",
        "torch.round(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS8ZZL99qukY",
        "outputId": "5af91c41-25f4-42b2-8b7d-a50a7daa9c2e"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.]], grad_fn=<RoundBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Logistic Multilabel Classification with MNIST"
      ],
      "metadata": {
        "id": "Mb4BHTU5yfbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "dw40Q27kyqZB"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNINST Dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download=True)"
      ],
      "metadata": {
        "id": "va-h8z_IzN6u"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "tO2chqa0zpvW"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "input_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "num_epochs = 5\n",
        "learning_rate = 5e-3"
      ],
      "metadata": {
        "id": "tCJ-Y6Oxz2-b"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "metadata": {
        "id": "btmYfeNK0eMR"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer\n",
        "# 주의! : nn.CrossEntropyLoss()는 내부에서 softmax 계산을 하기때문에 모델에 softmax를 달아놓으면 안됩니다.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1s_FlTjOzHC8"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "train_step = 1\n",
        "total_step = len(train_loader) * num_epochs\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # Train Step\n",
        "    for batch_idx, (images, labels) in enumerate(\n",
        "        tqdm(train_loader, position=0, leave=True, desc='train')\n",
        "        ):\n",
        "\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, input_size)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if train_step%500 == 0:\n",
        "            print(f'Epoch [{epoch}/{num_epochs}], Step [{train_step}/{total_step}], Loss : {loss.item():.4f}')\n",
        "        train_step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tVH_o2J1B7y",
        "outputId": "97ecc226-1202-45f4-9719-90516fc868e2"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  29%|██▉       | 540/1875 [00:01<00:04, 272.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [500/9375], Loss : 1.3212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  56%|█████▌    | 1047/1875 [00:03<00:03, 267.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [1000/9375], Loss : 0.7562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  82%|████████▏ | 1532/1875 [00:05<00:01, 274.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [1500/9375], Loss : 0.5763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 1875/1875 [00:06<00:00, 271.93it/s]\n",
            "train:   9%|▉         | 171/1875 [00:00<00:06, 278.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Step [2000/9375], Loss : 0.4785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  35%|███▌      | 657/1875 [00:02<00:04, 281.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Step [2500/9375], Loss : 0.7221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  63%|██████▎   | 1179/1875 [00:04<00:02, 278.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Step [3000/9375], Loss : 0.4369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  89%|████████▉ | 1666/1875 [00:06<00:00, 265.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Step [3500/9375], Loss : 0.4868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 1875/1875 [00:06<00:00, 275.03it/s]\n",
            "train:  15%|█▍        | 278/1875 [00:01<00:05, 268.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Step [4000/9375], Loss : 0.6367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  42%|████▏     | 781/1875 [00:02<00:04, 267.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Step [4500/9375], Loss : 0.5098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  69%|██████▊   | 1286/1875 [00:05<00:02, 249.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Step [5000/9375], Loss : 0.6528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  96%|█████████▋| 1806/1875 [00:07<00:00, 283.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Step [5500/9375], Loss : 0.9115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 1875/1875 [00:07<00:00, 254.90it/s]\n",
            "train:  23%|██▎       | 430/1875 [00:01<00:05, 279.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Step [6000/9375], Loss : 0.2194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  49%|████▉     | 924/1875 [00:03<00:03, 276.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Step [6500/9375], Loss : 0.4923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  75%|███████▌  | 1409/1875 [00:05<00:01, 274.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Step [7000/9375], Loss : 0.5085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 1875/1875 [00:06<00:00, 278.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Step [7500/9375], Loss : 0.3440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  30%|██▉       | 557/1875 [00:01<00:04, 277.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Step [8000/9375], Loss : 0.4721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  56%|█████▌    | 1042/1875 [00:03<00:03, 274.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Step [8500/9375], Loss : 0.2898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  81%|████████▏ | 1527/1875 [00:05<00:01, 276.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Step [9000/9375], Loss : 0.4732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 1875/1875 [00:06<00:00, 274.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# Test단계에서는 gradient를 계산하면 안됩니다.\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (images, labels) in enumerate(\n",
        "    tqdm(test_loader, position=0, leave=True, desc='test')\n",
        "    ):\n",
        "\n",
        "        images = images.reshape(-1, input_size)\n",
        "        outputs = model(images)\n",
        "        # print(outputs.data)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # print(preds)\n",
        "        # print(labels)\n",
        "        total += labels.size(0) # 매 배치마다의 labels 길이를 모두 더하면 test_data 전체 길이가 나옵니다.\n",
        "        correct += (preds == labels).sum()\n",
        "\n",
        "    print(f'Acc of 10000 test images : {100*correct/total:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QffR_nN9z2zt",
        "outputId": "ddff7222-4569-434a-e8af-3cf6303dea96"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 313/313 [00:01<00:00, 185.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc of 10000 test images : 89.9200%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "torch.save(model.state_dict(), 'params.ckpt')"
      ],
      "metadata": {
        "id": "xzjZDu7qzHH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}